{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the house.jpg file for this task. Use the Gaussian blur function to blur at least one of the windows. Use 13x13 size kernel for the blur.\n",
    "\n",
    "Additionally, you will need to apply Canny edge detection on the original house image. You must apply 2 of these edge detections; one on the original picture and second on a slightly blurred picture. Use same threshold values on both edge detections.\n",
    "\"\"\"\n",
    "\n",
    "img = cv2.imread('house.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Apply Canny edge detection on a slightly blurred picture\n",
    "blurred = cv2.GaussianBlur(img, (13, 13), 0)\n",
    "\n",
    "# Apply Canny edge detection on the original house image\n",
    "edges = cv2.Canny(img, 100, 200)\n",
    "edges_blurred = cv2.Canny(blurred, 10, 80)\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Blurred', blurred)\n",
    "cv2.imshow('Edges', edges)\n",
    "cv2.imshow('Edges blurred', edges_blurred)\n",
    "cv2.imshow\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the square1 and square2 files for this task. Use the bitwise operations on these images to make an octagon as well as an 8-pointed star. (Think of the black pixels as 0 and the white pixels as 1 in the binary operations)\n",
    "\"\"\"\n",
    "\n",
    "square1 = cv2.imread(\"lab4_square1.jpg\")\n",
    "square1_not = cv2.bitwise_not(square1)\n",
    "square2 = cv2.imread(\"lab4_square2.jpg\")\n",
    "\n",
    "# Make an 8-pointed star\n",
    "star = cv2.bitwise_or(square1_not, square2)\n",
    "\n",
    "# Make an octagon\n",
    "octagon = cv2.bitwise_and(square1_not, square2)\n",
    "\n",
    "cv2.imshow('Octagon', octagon)\n",
    "cv2.imshow('Star', star)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the shapes.bmp image and change its color space to HSV (Hue, Saturation, Value). Then, use the inRange function to isolate each shape separately:\n",
    " cv2.inRange(hsv,np.array([hmin,smin,vmin]),np.array([hmax,smax,vmax]))\n",
    "\n",
    "You must manually determine the values for the above 6 parameters. H values go from 0 to 179. S and V values go from 0 to 255. Display all four results (black and white images) in four windows. Then, take a screenshot\n",
    "\n",
    "Hint: Experiment with V values first to remove the background white color.\n",
    "\"\"\"\n",
    "\n",
    "img = cv2.imread(\"lab4_shapes.bmp\")\n",
    "img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Isolate each shape separately\n",
    "# Blue\n",
    "blue = cv2.inRange(img_hsv, np.array([100, 100, 100]), np.array([120, 255, 255]))\n",
    "\n",
    "# Green\n",
    "green = cv2.inRange(img_hsv, np.array([40, 100, 100]), np.array([80, 255, 255]))\n",
    "\n",
    "# Red\n",
    "red = cv2.inRange(img_hsv, np.array([130, 100, 100]), np.array([179, 255, 255]))\n",
    "\n",
    "# Cyan\n",
    "cyan = cv2.inRange(img_hsv, np.array([80, 100, 100]), np.array([100, 255, 255]))\n",
    "\n",
    "cv2.imshow(\"Blue\", blue)\n",
    "cv2.imshow(\"Green\", green)\n",
    "cv2.imshow(\"Red\", red)\n",
    "cv2.imshow(\"Cyan\", cyan)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In the previous task, you acquired binary \"masks\" for each shape. In this task, you will determine the center of each shape. Using the code from the previous task, place a yellow circle at the center point of all shapes in the shapes.jpg image. Your screenshot must show a single image (shapes.jpg) with the center points marked.\n",
    "\n",
    "To find the center point (cx, cy) in an image (img), use the moments function as shown in the code example:\n",
    "\n",
    "M = cv2.moments (img)\n",
    "if M['m00'] > 0:\n",
    "   \tcx = int(M['m10']/M['m00'])\n",
    "   \tcy = int(M['m01']/M['m00'])\n",
    "\"\"\"\n",
    "\n",
    "M_blue = cv2.moments(blue)\n",
    "M_green = cv2.moments(green)\n",
    "M_red = cv2.moments(red)\n",
    "M_cyan = cv2.moments(cyan)\n",
    "\n",
    "if M_blue['m00'] > 0:\n",
    "\tcx_blue = int(M_blue['m10']/M_blue['m00'])\n",
    "\tcy_blue = int(M_blue['m01']/M_blue['m00'])\n",
    " \n",
    "if M_green['m00'] > 0:\n",
    "\tcx_green = int(M_green['m10']/M_green['m00'])\n",
    "\tcy_green = int(M_green['m01']/M_green['m00'])\t\n",
    " \n",
    "if M_red['m00'] > 0:\n",
    "\tcx_red = int(M_red['m10']/M_red['m00'])\n",
    "\tcy_red = int(M_red['m01']/M_red['m00'])\n",
    " \n",
    "if M_cyan['m00'] > 0:\n",
    "\tcx_cyan = int(M_cyan['m10']/M_cyan['m00'])\n",
    "\tcy_cyan = int(M_cyan['m01']/M_cyan['m00'])\n",
    " \n",
    "cv2.circle(img, (cx_blue, cy_blue), 5, (0, 255, 255), -1)\n",
    "cv2.circle(img, (cx_green, cy_green), 5, (0, 255, 255), -1)\n",
    "cv2.circle(img, (cx_red, cy_red), 5, (0, 255, 255), -1)\n",
    "cv2.circle(img, (cx_cyan, cy_cyan), 5, (0, 255, 255), -1)\n",
    "\n",
    "cv2.imshow(\"Shapes\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the persp.jpg file for this task. Apply perspective transformation by using the four corners in the quadrilateral and map them to the four outer corners of the image file. The final result should be a flat, rectangular image (the width/height ratio in the final image is 3/4)\n",
    "\"\"\"\n",
    "\n",
    "img = cv2.imread(\"lab4_persp.jpg\")\n",
    "\n",
    "rows, cols, ch = img.shape\n",
    "pts1 = np.float32([[34, 18], [282, 61], [217, 548], [397, 393]])\n",
    "pts2 = np.float32([[0, 0], [420, 0], [0, 560], [420, 560]])\n",
    "\n",
    "M = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "dst = cv2.warpPerspective(img, M, (cols, rows))\n",
    "\n",
    "cv2.imshow(\"Perspective\", dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab Task 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the robot_green_bg file for this task. Using your knowledge from task 3, replace the green color of the background with red by scanning through each pixel. You can use RGB or HSV color space for this task. The following syntax examples will help:\n",
    "\n",
    "    •\tTo check a pixel color in blue channel:\n",
    "                    if img[i,j,0] < 100\n",
    "\n",
    "    •\tTo set a pixel color as black:\n",
    "                    img[i,j,:] = (0,0,0)\n",
    "\n",
    "Take a screenshot of the picture with the modified background. Next, load the road picture. Modify the code so that the robot is placed on the road picture. You must go through each pixel in the image. You can place the robot anywhere but the entire robot must be visible. Take the screenshot.\n",
    "\"\"\"\n",
    "\n",
    "# Replace the green color of the background with red\n",
    "img = cv2.imread(\"lab4_robot_green_bg.bmp\")\n",
    "img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "rows, cols, ch = img.shape\n",
    "\n",
    "# Through HSV color space\n",
    "green = cv2.inRange(img_hsv, np.array([40, 100, 100]), np.array([80, 255, 255]))\n",
    "green[green > 0] = 255\n",
    "img[green == 255] = (0, 0, 255)\n",
    "\n",
    "cv2.imshow(\"Robot_HSV\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place the robot on the road picture\n",
    "img = cv2.imread(\"lab4_robot_green_bg.bmp\")\n",
    "img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "img_road = cv2.imread(\"lab4_road.jpg\")\n",
    "rows, cols, ch = img.shape\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        if img[i, j, 0] < 100 and img[i, j, 1] > 100 and img[i, j, 2] < 100:\n",
    "            pass\n",
    "        else:\n",
    "            img_road[i, j, :] = img[i, j, :]\n",
    "\n",
    "cv2.imshow(\"Robot on the road\", img_road)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
